---
layout: default
---
<body>
    <section class="main-content">
      <h1 id="cs7641-project">CS7641-Project Team 17</h1>

<h2 id="introductionbackground">Introduction/Background</h2>
<p>At present, the visually impaired people use a simple stick for navigation. However, the use of such a stick does not enable them to navigate independently. If they ever get into an unknown environment, the most that they can do, without any external help, is detect stationary obstacles around them. Unfortunately, they cannot make any decision based on a comprehensive understanding of the environment. </p>
<p>To address this problem, we intend to develop a Machine Learning model for generating accurate visual understanding of a given scene. A model of this kind can potentially be integrated into an e-stick which assists the visually impaired and enables them to move with the same ease and confidence as normally sighted people.
</p>
        
<h2 id="problem-definition">Problem Definition</h2>
<p>Our project aims at developing a software framework that can detect objects from images and then answer questions based on the content of those images. From a big picture perspective, this project is a stepping stone towards engineering a system that can capture real-time images to provide high-level contextual information about the surroundings. Combining such a system with a mapping and navigation module and integrating into an e-stick would enable the visually impaired to navigate independently.
</p>
        
<h2 id="methodology">Methodology</h2>
<h3 id="datasets">Datasets</h3>
<ul>
<li>Object Detection dataset - this dataset consists of images and object categories that the images encompass. 
</li>
<li>Questions and Answers dataset - this dataset consists of text based questions. A query will be a question that the visually impaired person will ask to the system, and an answer would be the model provided output. </li>
</ul>
        
<h3 id="machine_learning_checkpoints">Machine Learning Checkpoints</h3>
<ul>
<li>Using supervised algorithms such as CNN, we will build the object detection model to detect objects in the surroundings 
</li>
<li>Using unsupervised and semi-supervised algorithms such as vanilla-RNN, LSTM, GRU, we will develop a text detection system to understand the query input. 
</li>
<li>We will later build a multi-modal model combining the above models to achieve our goal. We will then perform a comparison of the results of our model with existing state-of-the-art (SOTA) models. 
</li>
    
<p align="left">So when integrated into an e-stick, the visually impaired will be providing a speech input to the system, which will be converted into text. Our model will use this text as an input and provide an answer to the query in text, which can then again be converted into a voice-controlled output for the visually impaired to understand.
</p>
    
       
        
<p>Note: The following images of the tables only output the head of each table, the actual data is much larger</p>
<h4 id="table-1-raw-movie-dataset">Table 1: Raw Movie Dataset</h4>
<p><img src="https://user-images.githubusercontent.com/31360127/113789931-29b50e80-970e-11eb-8feb-0ecbb705db23.png" alt="image" /></p>
<h4 id="table-2-raw-plot-dataset">Table 2: Raw Plot Dataset</h4>
<p><img src="https://user-images.githubusercontent.com/31360127/113789954-3a658480-970e-11eb-868c-e000181796a6.png" alt="image" /></p>
<h4 id="table-3-clean-merged-dataset">Table 3: Clean Merged Dataset</h4>
<p><img src="https://user-images.githubusercontent.com/31360127/113789655-882dbd00-970d-11eb-89f1-c9a851a6f7c4.png" alt="image" /></p>

<h3 id="model-architecture-training-and-evaluation-metrics">Model Architecture, Training, and Evaluation Metrics</h3>
<p>The processed data was split into training and testing tests with a ratio of 80% to 20%, respectively. The input plot features in text-form were converted to numerical values through a Tfidf Vectorizer by fitting and transforming the text; Tfidf was chosen as the medium for conversion due to its effective text characterization using word frequency across all the ‘documents.’ Currently, the main model architecture is based on a Gaussian Naive Bayes model with a one versus rest classifier as implemented in the scikit-learn library. As we all know, Naive Bayes makes the drastic assumption that features are independent of one another and is subject to change depending on continued testing and accuracy. The main metrics for model evaluation were general accuracy and the F-score (precision/recall) between the actual and predicted genre labels. These provide an indication of the efficiacy of the machine learning model and need for further modifications and optimizations.</p>

<h2 id="results">Results</h2>
<p>We trained multiple classifiers using Gaussian Naive Bayes, Logistic Regression, and a Decision Tree Classifier. From our accuracy score and our F-score we obtained the following results (Note: The closer the F-score and Accuracy is to 1, the more optimal the predictions):</p>
<h4 id="table-4-gaussian-naive-bayes-metrics">Table 4: Gaussian Naive Bayes Metrics</h4>
<p><img src="https://user-images.githubusercontent.com/55769184/116170430-d7e02280-a6d4-11eb-9425-a1038f616bc0.png" alt="image" /></p>
<h4 id="table-5-logistic-regression-metrics">Table 5: Logistic Regression Metrics</h4>
<p><img src="https://user-images.githubusercontent.com/55769184/116170437-dadb1300-a6d4-11eb-8569-cca95c9b8a75.png" alt="image" /></p>
<h4 id="table-6-decision-tree-metrics">Table 6: Decision Tree Metrics</h4>
<p><img src="https://user-images.githubusercontent.com/55769184/116170420-d31b6e80-a6d4-11eb-9002-981dfc10b799.png" alt="image" /></p>
<h4 id="table-7-example-movie-genre-prediction">Table 7: Example Movie Genre Prediction</h4>
<p><img src="https://user-images.githubusercontent.com/31360127/116178459-9b67f300-a6e3-11eb-8bab-b5624f66d3c0.png" alt="image" /></p>

<h2 id="discussion">Discussion</h2>
<p>From our results it seems that our approach in further cleaning the data and limiting genre selection to independent genres was a great way of fine tuning the model.</p>

<p>During this iteration, we added a new Decision Tree model which produced genre predictions resulting in a greater accuracy of 44 percent. Our previous approaches also increased greatly with a 53 percent accuracy for Gaussian Naive Bayes and a 62 percent accuracy with Logistic Regression. These percentage values are significant improvements from last time, with previous percentages of 25 and 30 for Gaussian Naive Bayes and Logistic Regression respectively.</p>

<p>We found out that the reason why the percentages were so low the first time is because low accuracy was likely to result from the singular genre extraction technique implemented which assigns only a single genre to each movie in the dataset out of its multilabel set, as the model may have clashing predictions which may be accurate when considering all the genres that characterize the movie. For example, if we take a movie like Star Wars, this movie could be considered a sci-fi movie, but it could also be considered an adventure movie, and one label is not objectively more accurate to use than the other. Because of this, if we tested our model for Star Wars and used adventure as our single genre to classify it under, our model could predict that it is a sci-fi movie, and even though this is also true, it would be seen as a failure by the model, resulting in a false negative.</p>

<p>In our initial attempts, there was inherent overfitting due to certain genres fitting a higher number of movies than other genres that we used, as could be very clearly seen by the fact that we had almost triple the number of Thrillers as we did Romantic Comedies. Because of this discrepancy in size, our model became overtrained for identifying some genres and undertrained for identifying others. However, this time, we limited genre selection to an array of independent (commonly mutually exclusive) genres, which increased accuracy tremendously. For example, having both Action and Crime Fiction genres as potential genres increased ambiguity for the univariate predictions due to there being overlap between these two genres in many movies, whereas Sci-fi and Romance had much higher accuracy due to Sci-Fi Romance movies being much more uncommon than Action Crime Fiction movies. Therefore, we produced more accurate results in the final stages through additional testing and experimentation.</p>

<h2 id="conclusions">Conclusions</h2>
<p>The final results of our movie genre prediction classification model were initially very unexpected as we believed that due to the massive size of the dataset and single label predictions, there would be an extremely high accuracy. As we continued on and further investigated the shape and dependencies within the dataset and mechanics of the model, we understood why we should have expected lower accuracies as a result of the non-mutually exclusive nature of movie genres as discussed previously in the report. While the accuracy is not optimal, it was increased substantially over the course of our experimentation and reached a level sufficient for semi-accurate genre tagging with the dataset manipulation. In future iterations, potentially choosing a dataset with an additional number of features including movie reviews could potentially increase the performance of our model by providing an extra facet to train on. Moreover, a substantial improvement in the model architecture could be to implement a multilabel classifier which is able to input and output an array of several genres per movie which could completely circumvent the posed issues. All in all, however, the results of this project have been extremely promising and have provided a foundational understanding for future research and development in the field of genre tagging.</p>

<h2 id="group-member-contributions">Group Member Contributions</h2>
<p>Alvin Bao - Worked on training the 3 models, wrote the results, and tuned the models for better accuracy.<br />
Feras Alsaiari - Worked on training the 3 models, wrote the conclusion, and helped come up with the model architectures.<br />
Jacob Smith - Researched our topic and found CMU dataset, wrote the discussion section, and wrote the introduction &amp; problem definition.<br />
Mohammad Aqdas Imran - Cleaned the data, wrote the discussion section, and wrote the data cleaning section.<br />
Parth Desai - Cleaned the data, wrote the discussion section, and made the video for our report.</p>

<h2 id="references">References</h2>
<p>[1] Learning Latent Personas of Film Characters David Bamman, Brendan O’Connor, and Noah A. Smith ACL 2013, Sofia, Bulgaria, August 2013 http://www.cs.cmu.edu/~ark/personas/</p>

<p>[2] Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python. O’Reilly Media Inc https://www.nltk.org/</p>

<p>[3] A. Rahman and M. S. Hossen, “Sentiment Analysis on Movie Review Data Using Machine Learning Approach,” 2019 International Conference on Bangla Speech and Language Processing (ICBSLP), Sylhet, Bangladesh, 2019, pp. 1-4, doi: 10.1109/ICBSLP47725.2019.201470.</p>


      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/baoalvin1/CS4641-project">CS4641-project</a> is maintained by <a href="https://github.com/baoalvin1">baoalvin1</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </section>

  </body>
    
